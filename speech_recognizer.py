#!/usr/bin/env python3
"""
Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª - ÙŠØ¯Ø¹Ù… Vosk Ùˆ Whisper Ùˆ Google Speech Recognition
"""

import wave
import tempfile
import os
import threading
import time
import numpy as np

try:
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ openai-whisper (Ø§Ù„ØµØ­ÙŠØ­)
    try:
        import whisper
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† whisper Ù‡Ùˆ openai-whisper ÙˆÙ„ÙŠØ³ whisper.py Ø§Ù„Ù‚Ø¯ÙŠÙ…
        if hasattr(whisper, 'load_model'):
            WHISPER_AVAILABLE = True
        else:
            # whisper.py Ø§Ù„Ù‚Ø¯ÙŠÙ… - Ù„ÙŠØ³ Ù…ØªÙˆØ§ÙÙ‚Ø§Ù‹
            WHISPER_AVAILABLE = False
            whisper = None
    except (ImportError, TypeError, AttributeError):
        WHISPER_AVAILABLE = False
        whisper = None
except Exception:
    WHISPER_AVAILABLE = False
    whisper = None

try:
    from vosk import Model, KaldiRecognizer
    VOSK_AVAILABLE = True
except ImportError:
    VOSK_AVAILABLE = False

try:
    import speech_recognition as sr
    GOOGLE_SR_AVAILABLE = True
except ImportError:
    GOOGLE_SR_AVAILABLE = False

try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError:
    PYAUDIO_AVAILABLE = False

try:
    import sounddevice as sd
    SOUNDDEVICE_AVAILABLE = True
except ImportError:
    SOUNDDEVICE_AVAILABLE = False

import json


class SpeechRecognizer:
    """Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª Ù…Ø¹ Ø¯Ø¹Ù… Ø¹Ø¯Ø© Ù…Ø­Ø±ÙƒØ§Øª"""
    
    def __init__(self, engine='vosk', model_path=None, language='ar', 
                 use_google_fallback=False, offline_only=False):
        """
        ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ¹Ø±Ù
        
        Args:
            engine: 'whisper' Ø£Ùˆ 'vosk' Ø£Ùˆ 'google'
            model_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ù„Ù„Ù€ Vosk)
            language: Ø§Ù„Ù„ØºØ© ('ar' Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©)
            use_google_fallback: Ø§Ø³ØªØ®Ø¯Ø§Ù… Google ÙƒØ§Ø­ØªÙŠØ§Ø·ÙŠ Ø¹Ù†Ø¯ Ø§Ù„ÙØ´Ù„
            offline_only: Ø§Ù„Ø¹Ù…Ù„ Ø¨Ø¯ÙˆÙ† Ø¥Ù†ØªØ±Ù†Øª ÙÙ‚Ø· (ØªØ¹Ø·ÙŠÙ„ Google)
        """
        self.engine = engine.lower()
        self.language = language
        self.is_listening = False
        self.audio_stream = None
        self.pyaudio_instance = None
        self.use_sounddevice = False  # Ø¹Ù„Ø§Ù…Ø© Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… sounddevice
        self.audio_queue = []  # Ù‚Ø§Ø¦Ù…Ø© Ø¥Ø·Ø§Ø±Ø§Øª sounddevice
        self.callback = None
        self.use_google_fallback = use_google_fallback and not offline_only
        self.offline_only = offline_only
        
        self.vosk_models = {}
        self.current_vosk_model = None
        self.vosk_recognizer = None
        self.processing = False  # Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„Ù„ØªØ¹Ø±Ù ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†
        
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø®ØªØ§Ø±
        if self.engine == 'whisper':
            self._init_whisper()
        elif self.engine == 'vosk':
            self._init_vosk(model_path)
        elif self.engine == 'google':
            if not GOOGLE_SR_AVAILABLE:
                raise ImportError("Google Speech Recognition ØºÙŠØ± Ù…Ø«Ø¨Øª. Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØªÙ‡: pip install SpeechRecognition")
            if offline_only:
                raise ValueError("Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Google ÙÙŠ ÙˆØ¶Ø¹ offline_only")
        else:
            raise ValueError(f"Ù…Ø­Ø±Ùƒ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…: {engine}")
    
    def _init_whisper(self):
        """ØªÙ‡ÙŠØ¦Ø© Whisper"""
        if not WHISPER_AVAILABLE or whisper is None:
            raise ImportError(
                "Whisper ØºÙŠØ± Ù…Ø«Ø¨Øª Ø£Ùˆ ØºÙŠØ± Ù…ØªÙˆØ§ÙÙ‚.\n"
                "Ø§Ù„Ø­Ù„:\n"
                "1. Ù‚Ù… Ø¨Ø¥Ù„ØºØ§Ø¡ ØªØ«Ø¨ÙŠØª whisper Ø§Ù„Ø®Ø§Ø·Ø¦: pip uninstall whisper\n"
                "2. Ø«Ù… Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØª openai-whisper: pip install openai-whisper\n"
                "Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… Vosk Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„Ùƒ"
            )
        
        try:
            print("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Whisper...")
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… base ÙƒÙ†Ù…ÙˆØ°Ø¬ Ø§ÙØªØ±Ø§Ø¶ÙŠ (ÙŠÙ…ÙƒÙ† ØªØºÙŠÙŠØ±Ù‡ Ø¥Ù„Ù‰ medium Ø£Ùˆ large Ù„Ù„Ø¯Ù‚Ø© Ø§Ù„Ø£ÙØ¶Ù„)
            self.whisper_model = whisper.load_model("base")
            print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Whisper Ø¨Ù†Ø¬Ø§Ø­!")
        except Exception as e:
            raise ImportError(
                f"ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Whisper: {e}\n"
                "ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª openai-whisper Ø§Ù„ØµØ­ÙŠØ­: pip install openai-whisper"
            )
    
    def _init_vosk(self, model_path):
        """ØªÙ‡ÙŠØ¦Ø© Vosk"""
        if not VOSK_AVAILABLE:
            raise ImportError("Vosk ØºÙŠØ± Ù…Ø«Ø¨Øª. Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØª: pip install vosk")
        
        if not model_path:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ù…Ø¬Ù„Ø¯ models
            possible_paths = [
                "models/vosk-model-ar",
                "../models/vosk-model-ar",
                "vosk-model-ar-0.22",
                "models/vosk-model-ar-0.22-linto-1.1.0",
                "../models/vosk-model-ar-0.22-linto-1.1.0"
            ]
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… ModelManager Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            try:
                from model_manager import ModelManager
                manager = ModelManager()
                found_path = manager.get_model_path(self.language)
                if found_path:
                    model_path = str(found_path)
            except:
                pass
            
            if not model_path:
                for path in possible_paths:
                    if os.path.exists(path):
                        model_path = path
                        break
            
            if not model_path:
                raise FileNotFoundError(
                    "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ Vosk Ø§Ù„Ø¹Ø±Ø¨ÙŠ. "
                    "Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„Ù‡ Ù…Ù†: https://alphacephei.com/vosk/models"
                )
        
        print(f"ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Vosk Ù…Ù†: {model_path}...")
        self.vosk_model = Model(model_path)
        self.vosk_recognizer = KaldiRecognizer(self.vosk_model, 16000)
        self.vosk_recognizer.SetWords(True)
        print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Vosk Ø¨Ù†Ø¬Ø§Ø­!")
    
    def switch_language(self, language: str, model_path=None):
        """
        ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„Ù„ØºØ© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„
        
        Args:
            language: Ø±Ù…Ø² Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯
            model_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ù„Ù„Ù€ Vosk)
        """
        if self.is_listening:
            print("âš ï¸ Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„Ù„ØºØ© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„")
            return False
        
        self.language = language
        
        if self.engine == 'vosk':
            try:
                self._init_vosk(model_path)
                print(f"âœ… ØªÙ… Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù„ØºØ©: {language}")
                return True
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„Ù„ØºØ©: {e}")
                return False
        elif self.engine == 'whisper':
            print(f"âœ… ØªÙ… Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù„ØºØ©: {language}")
            return True
        
        return True
    
    def start_recording(self):
        """Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„"""
        if self.is_listening:
            return
        
        self.is_listening = True
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØµÙˆØª
        if not PYAUDIO_AVAILABLE and not SOUNDDEVICE_AVAILABLE:
            raise ImportError(
                "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…ÙƒØªØ¨Ø© ØµÙˆØª Ù…ØªØ§Ø­Ø©!\n"
                "Ø§Ù„Ø±Ø¬Ø§Ø¡ ØªØ«Ø¨ÙŠØª Ø¥Ø­Ø¯Ù‰ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:\n"
                "  pip install sounddevice  (Ù…Ø³ØªØ­Ø³Ù†)\n"
                "  pip install PyAudio"
            )
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
        use_sounddevice = SOUNDDEVICE_AVAILABLE and not PYAUDIO_AVAILABLE
        
        try:
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†
            print(f"ğŸ¤ Ø¬Ø§Ø±ÙŠ ÙØªØ­ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†... (Ø§Ø³ØªØ®Ø¯Ø§Ù… {'sounddevice' if use_sounddevice else 'PyAudio'})")
            
            if use_sounddevice:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… sounddevice
                print(f"ğŸ“Š Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„ØµÙˆØª Ø§Ù„Ù…ØªØ§Ø­Ø©:")
                devices = sd.query_devices()
                default_input = sd.query_devices(kind='input')
                print(f"ï¿½ï¸ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ: {default_input['name']}")
                
                self.use_sounddevice = True
                self.audio_queue = []
            else:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… PyAudio
                self.pyaudio_instance = pyaudio.PyAudio()
                
                # Ø·Ø¨Ø§Ø¹Ø© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©
                print(f"ğŸ“Š Ø¹Ø¯Ø¯ Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„ØµÙˆØª: {self.pyaudio_instance.get_device_count()}")
                default_input = self.pyaudio_instance.get_default_input_device_info()
                print(f"ğŸ™ï¸ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ: {default_input['name']}")
                
                self.audio_stream = self.pyaudio_instance.open(
                    format=pyaudio.paInt16,
                    channels=1,
                    rate=16000,
                    input=True,
                    frames_per_buffer=2000,
                    input_device_index=None
                )
                
                self.audio_stream.start_stream()
                self.use_sounddevice = False
            
            print("âœ… ØªÙ… ÙØªØ­ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ø¨Ù†Ø¬Ø§Ø­!")
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙØªØ­ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†: {e}")
            self.is_listening = False
            if self.pyaudio_instance:
                try:
                    self.pyaudio_instance.terminate()
                except:
                    pass
                self.pyaudio_instance = None
            raise Exception(
                f"ÙØ´Ù„ ÙÙŠ ÙØªØ­ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†!\n\n"
                f"Ø§Ù„Ø®Ø·Ø£: {e}\n\n"
                f"Ø§Ù„Ø­Ù„ÙˆÙ„:\n"
                f"1. ØªØ£ÙƒØ¯ Ù…Ù† ØªÙˆØµÙŠÙ„ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†\n"
                f"2. ØªØ­Ù‚Ù‚ Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙˆØª ÙÙŠ Windows\n"
                f"3. Ø£Ø¹Ø· Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†\n"
                f"4. Ø£Ø¹Ø¯ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø¨ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„\n"
                f"5. Ø¬Ø±Ø¨ Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ø¢Ø®Ø± Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹"
            )
    
    def stop_recording(self):
        """Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¨Ø£Ù…Ø§Ù†"""
        print("â¹ï¸ Ø¬Ø§Ø±ÙŠ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„...")
        self.is_listening = False
        
        # Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ù„Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
        import time
        time.sleep(0.1)
        
        # Ø¥ÙŠÙ‚Ø§Ù Ø­Ø³Ø¨ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
        if hasattr(self, 'use_sounddevice') and self.use_sounddevice:
            # sounddevice Ù„Ø§ ØªØ­ØªØ§Ø¬ Ù„Ø¥ØºÙ„Ø§Ù‚ stream
            print("âœ… ØªÙ… Ø¥ÙŠÙ‚Ø§Ù sounddevice")
        else:
            # Ø¥ÙŠÙ‚Ø§Ù ÙˆØ¥ØºÙ„Ø§Ù‚ PyAudio stream
            if self.audio_stream:
                try:
                    if self.audio_stream.is_active():
                        self.audio_stream.stop_stream()
                    self.audio_stream.close()
                except Exception as e:
                    print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø¥ÙŠÙ‚Ø§Ù audio_stream: {e}")
                finally:
                    self.audio_stream = None
            
            # Ø¥Ù†Ù‡Ø§Ø¡ PyAudio
            if self.pyaudio_instance:
                try:
                    self.pyaudio_instance.terminate()
                except Exception as e:
                    print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ù‡Ø§Ø¡ PyAudio: {e}")
                finally:
                    self.pyaudio_instance = None
        
        print("âœ… ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­")
    
    def recognize_audio_file(self, audio_file_path):
        """Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù…Ù„Ù ØµÙˆØªÙŠ"""
        text = ""
        
        if self.engine == 'whisper':
            text = self._recognize_with_whisper_file(audio_file_path)
        elif self.engine == 'vosk':
            text = self._recognize_with_vosk_file(audio_file_path)
        elif self.engine == 'google':
            text = self._recognize_with_google_file(audio_file_path)
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Google ÙƒØ§Ø­ØªÙŠØ§Ø·ÙŠ Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        if not text and self.use_google_fallback and GOOGLE_SR_AVAILABLE:
            print("ğŸ”„ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Google Speech Recognition ÙƒØ§Ø­ØªÙŠØ§Ø·ÙŠ...")
            text = self._recognize_with_google_file(audio_file_path)
        
        return text
    
    def _recognize_with_whisper_file(self, audio_file_path):
        """Ø§Ù„ØªØ¹Ø±Ù Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Whisper Ù…Ù† Ù…Ù„Ù"""
        try:
            result = self.whisper_model.transcribe(
                audio_file_path,
                language=self.language,
                task='transcribe'
            )
            return result['text'].strip()
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Whisper: {e}")
            return ""
    
    def _recognize_with_vosk_file(self, audio_file_path):
        """Ø§Ù„ØªØ¹Ø±Ù Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Vosk Ù…Ù† Ù…Ù„Ù"""
        try:
            wf = wave.open(audio_file_path, "rb")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙŠØºØ© Ø§Ù„Ù…Ù„Ù
            if wf.getnchannels() != 1 or wf.getcomptype() != "NONE":
                print("âŒ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ù…Ù„Ù Ø¨ØµÙŠØºØ© mono PCM")
                return ""
            
            recognizer = KaldiRecognizer(self.vosk_model, wf.getframerate())
            recognizer.SetWords(True)
            
            text_parts = []
            
            while True:
                data = wf.readframes(4000)
                if len(data) == 0:
                    break
                
                if recognizer.AcceptWaveform(data):
                    result = json.loads(recognizer.Result())
                    if result.get('text'):
                        text_parts.append(result['text'])
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
            final_result = json.loads(recognizer.FinalResult())
            if final_result.get('text'):
                text_parts.append(final_result['text'])
            
            wf.close()
            return " ".join(text_parts).strip()
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Vosk: {e}")
            return ""
    
    def _recognize_with_google_file(self, audio_file_path):
        """Ø§Ù„ØªØ¹Ø±Ù Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Google Speech Recognition Ù…Ù† Ù…Ù„Ù"""
        if not GOOGLE_SR_AVAILABLE:
            return ""
        
        try:
            recognizer = sr.Recognizer()
            
            with sr.AudioFile(audio_file_path) as source:
                audio = recognizer.record(source)
            
            google_lang_map = {
                'ar': 'ar-SA',
                'en': 'en-US',
                'ko': 'ko-KR',
                'ru': 'ru-RU',
                'tr': 'tr-TR'
            }
            
            google_lang = google_lang_map.get(self.language, self.language)
            
            text = recognizer.recognize_google(audio, language=google_lang)
            return text.strip()
            
        except sr.UnknownValueError:
            print("âŒ Google Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† ÙÙ‡Ù… Ø§Ù„ØµÙˆØª")
            return ""
        except sr.RequestError as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø®Ø¯Ù…Ø© Google: {e}")
            return ""
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Google Speech Recognition: {e}")
            return ""
    
    def record_and_recognize(self, duration=5):
        """ØªØ³Ø¬ÙŠÙ„ ØµÙˆØªÙŠ Ù„ÙØªØ±Ø© Ù…Ø­Ø¯Ø¯Ø© ÙˆØ§Ù„ØªØ¹Ø±Ù Ø¹Ù„ÙŠÙ‡"""
        if not self.is_listening:
            self.start_recording()
        
        frames = []
        
        for _ in range(0, int(16000 / 8000 * duration)):
            if hasattr(self, 'use_sounddevice') and self.use_sounddevice:
                data = sd.rec(8000, samplerate=16000, channels=1, dtype='int16', blocking=True)
                data = data.tobytes()
            else:
                data = self.audio_stream.read(8000, exception_on_overflow=False)
            frames.append(data)
        
        # Ø­ÙØ¸ ÙÙŠ Ù…Ù„Ù Ù…Ø¤Ù‚Øª
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        temp_file.close()
        
        with wave.open(temp_file.name, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)  # 16-bit = 2 bytes
            wf.setframerate(16000)
            wf.writeframes(b''.join(frames))
        
        # Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª
        text = self.recognize_audio_file(temp_file.name)
        
        # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
        os.unlink(temp_file.name)
        
        return text
    
    def listen_continuous(self, callback, phrase_time_limit=8, pause_threshold=0.8):
        """
        Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ø§Ù„Ù…Ø³ØªÙ…Ø± Ù„Ù„ØµÙˆØª (Ù…Ø­Ø³Ù‘Ù† Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ± Ù„Ù„Ø³Ø±Ø¹Ø©)
        
        Args:
            callback: Ø¯Ø§Ù„Ø© ÙŠØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¤Ù‡Ø§ Ø¹Ù†Ø¯ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù†Øµ
            phrase_time_limit: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ø·ÙˆÙ„ Ø§Ù„Ø¬Ù…Ù„Ø© (Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ) - Ø§ÙØªØ±Ø§Ø¶ÙŠ 8 Ø«ÙˆØ§Ù†
            pause_threshold: ÙˆÙ‚Øª Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø¹Ù†Ø¯ Ø§Ù„ØµÙ…Øª (Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ) - Ø§ÙØªØ±Ø§Ø¶ÙŠ 0.8 Ø«Ø§Ù†ÙŠØ©
        """
        self.callback = callback
        
        if not self.is_listening:
            self.start_recording()
        
        frames = []
        silence_start = None
        self.processing = False  # Ù…Ù†Ø¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©
        
        try:
            while self.is_listening:
                # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØª Ø­Ø³Ø¨ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
                if hasattr(self, 'use_sounddevice') and self.use_sounddevice:
                    # Ø§Ø³ØªØ®Ø¯Ø§Ù… sounddevice
                    data = sd.rec(2000, samplerate=16000, channels=1, dtype='int16', blocking=True)
                    data = data.tobytes()
                else:
                    # Ø§Ø³ØªØ®Ø¯Ø§Ù… PyAudio
                    data = self.audio_stream.read(2000, exception_on_overflow=False)
                
                frames.append(data)
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµÙ…Øª - Ù…Ø­Ø³Ù‘Ù† Ù„Ø£Ù‚ØµÙ‰ Ø³Ø±Ø¹Ø© Ù…Ù…ÙƒÙ†Ø©
                if len(frames) >= 2:  # ÙØ­Øµ ÙÙˆØ±ÙŠ - Ø¢Ø®Ø± Ø¥Ø·Ø§Ø±ÙŠÙ† ÙÙ‚Ø·
                    audio_data = b''.join(frames[-2:])  # Ø¢Ø®Ø± Ø¥Ø·Ø§Ø±ÙŠÙ† ÙÙ‚Ø· (Ø£Ø³Ø±Ø¹ Ù…Ù…ÙƒÙ†)
                    samples = np.frombuffer(audio_data, dtype=np.int16)
                    max_amplitude = np.max(np.abs(samples))
                else:
                    max_amplitude = 1000  # Ø§ÙØªØ±Ø§Ø¶ ÙˆØ¬ÙˆØ¯ ØµÙˆØª
                
                if max_amplitude < 500:  # Ø¹ØªØ¨Ø© Ø§Ù„ØµÙ…Øª Ù…Ø­Ø³Ù‘Ù†Ø© - 500 Ø£ÙØ¶Ù„ Ù…Ù† 250
                    if silence_start is None:
                        silence_start = time.time()
                    elif time.time() - silence_start > pause_threshold and not self.processing:
                        # ØªÙ… Ø§ÙƒØªØ´Ø§Ù ØµÙ…Øª - Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙˆØ±ÙŠØ©
                        if len(frames) > 2:  # Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ 0.1 Ø«Ø§Ù†ÙŠØ© Ù…Ù† Ø§Ù„ØµÙˆØª
                            self.processing = True
                            # Ø§Ø³ØªØ®Ø¯Ø§Ù… threading Ù„Ù„ØªØ¹Ø±Ù ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†
                            recognition_thread = threading.Thread(
                                target=self._process_recorded_audio_async,
                                args=(frames.copy(),)
                            )
                            recognition_thread.daemon = True
                            recognition_thread.start()
                        frames = []
                        silence_start = None
                else:
                    silence_start = None
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø¬Ù…Ù„Ø© (Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙˆØ±ÙŠØ©)
                if len(frames) > int(16000 / 4000 * phrase_time_limit) and not self.processing:
                    self.processing = True
                    recognition_thread = threading.Thread(
                        target=self._process_recorded_audio_async,
                        args=(frames.copy(),)
                    )
                    recognition_thread.daemon = True
                    recognition_thread.start()
                    frames = []
                    silence_start = None
                
                # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ£Ø®ÙŠØ± ØªÙ…Ø§Ù…Ø§Ù‹ - Ø£Ù‚ØµÙ‰ Ø³Ø±Ø¹Ø© Ù…Ù…ÙƒÙ†Ø©
                # time.sleep(0.005)  # ØªØ£Ø®ÙŠØ± Ø£Ø¯Ù†Ù‰ Ø¥Ù† Ù„Ø²Ù…
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹: {e}")
        finally:
            self.stop_recording()
    
    def _process_recorded_audio(self, frames):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø³Ø¬Ù„ (Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©)"""
        try:
            # Ø­ÙØ¸ ÙÙŠ Ù…Ù„Ù Ù…Ø¤Ù‚Øª
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
            temp_file.close()
            
            with wave.open(temp_file.name, 'wb') as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)  # 16-bit = 2 bytes
                wf.setframerate(16000)
                wf.writeframes(b''.join(frames))
            
            # Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª
            text = self.recognize_audio_file(temp_file.name)
            
            # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
            os.unlink(temp_file.name)
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø¯Ø§Ù„Ø© callback
            if text and self.callback:
                # ØªØµÙÙŠØ© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ Ø£Ùˆ Ø§Ù„Ù…Ø´ÙˆØ´Ø©
                text = text.strip()
                # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ (Ø£Ù‚Ù„ Ù…Ù† 2 Ø£Ø­Ø±Ù)
                if len(text) >= 2 and not self._is_noise(text):
                    self.callback(text)
                else:
                    print(f"âš ï¸ ØªÙ… ØªØ¬Ø§Ù‡Ù„ Ù†Øµ Ù…Ø´ÙˆØ´: '{text}'")
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª: {e}")
    
    def _process_recorded_audio_async(self, frames):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø³Ø¬Ù„ Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù† (Ø£Ø³Ø±Ø¹)"""
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Vosk Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹ (Ø£Ø³Ø±Ø¹ Ø¨ÙƒØ«ÙŠØ±)
            if self.engine == 'vosk' and self.vosk_recognizer:
                text = self._recognize_with_vosk_memory(frames)
                if text and self.callback:
                    self.callback(text)
                return
            
            # Ù„Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ø®Ø±Ù‰ØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
            temp_file.close()
            
            with wave.open(temp_file.name, 'wb') as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(16000)
                wf.writeframes(b''.join(frames))
            
            # Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª
            text = self.recognize_audio_file(temp_file.name)
            
            # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
            try:
                os.unlink(temp_file.name)
            except:
                pass
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø¯Ø§Ù„Ø© callback
            if text and self.callback:
                self.callback(text)
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª: {e}")
        finally:
            # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ø¹Ø¯ Ø§Ù†ØªÙ‡Ø§Ø¡ Thread
            self.processing = False
    
    def _recognize_with_vosk_memory(self, frames):
        """Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Vosk (Ø£Ø³Ø±Ø¹ Ø¨ÙƒØ«ÙŠØ±)"""
        try:
            audio_data = b''.join(frames)
            text_parts = []
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ø£Ù‚ØµÙ‰ Ø³Ø±Ø¹Ø© Ù…Ù…ÙƒÙ†Ø©
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø¯ÙˆÙ† ØªÙ‚Ø³ÙŠÙ… Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØµØºÙŠØ±Ø©
            if len(audio_data) <= 16000:  # Ø£Ù‚Ù„ Ù…Ù† Ø«Ø§Ù†ÙŠØ© ÙˆØ§Ø­Ø¯Ø©
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¨Ø§Ø´Ø±Ø© - Ø£Ø³Ø±Ø¹ Ø·Ø±ÙŠÙ‚Ø©
                if self.vosk_recognizer.AcceptWaveform(audio_data):
                    result = json.loads(self.vosk_recognizer.Result())
                    if result.get('text'):
                        text_parts.append(result['text'])
            else:
                # Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£ÙƒØ¨Ø±ØŒ Ø§Ø³ØªØ®Ø¯Ù… chunks ØµØºÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
                chunk_size = 1000  # Ø­Ø¬Ù… Ø£ØµØºØ± Ù…Ù…ÙƒÙ† Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø³Ø±Ø¹
                for i in range(0, len(audio_data), chunk_size):
                    chunk = audio_data[i:i + chunk_size]
                    
                    if self.vosk_recognizer.AcceptWaveform(chunk):
                        result = json.loads(self.vosk_recognizer.Result())
                        if result.get('text'):
                            text_parts.append(result['text'])
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© ÙÙˆØ±Ø§Ù‹
            final_result = json.loads(self.vosk_recognizer.FinalResult())
            if final_result.get('text'):
                text_parts.append(final_result['text'])
            
            return " ".join(text_parts).strip()
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Vosk Memory: {e}")
            return ""
    
    def _is_noise(self, text):
        """ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ø¶ÙˆØ¶Ø§Ø¡ Ø£Ùˆ ÙƒÙ„Ø§Ù… ØºÙŠØ± Ù…ÙÙ‡ÙˆÙ…"""
        text = text.strip().lower()
        
        # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø´ÙˆØ´Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ ØªØ¬Ø§Ù‡Ù„Ù‡Ø§
        noise_patterns = [
            'uh', 'um', 'ah', 'eh', 'mm', 'hmm',
            'Ø§Ù‡', 'Ø§Ù…', 'Ù…Ù…Ù…', 'Ù‡Ù…Ù…Ù…', 'Ø§Ø§Ø§', 'ÙŠÙŠÙŠ',
            '[noise]', '[silence]', '[music]',
        ]
        
        # ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ ÙŠØ­ØªÙˆÙŠ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø£Ø­Ø±Ù Ù…ØªÙƒØ±Ø±Ø©
        if len(set(text)) <= 2 and len(text) > 3:
            return True  # Ù…Ø«Ù„ "Ø§Ø§Ø§Ø§Ø§" Ø£Ùˆ "ÙŠÙŠÙŠÙŠ"
        
        # ÙØ­Øµ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø´ÙˆØ´Ø©
        for pattern in noise_patterns:
            if pattern in text:
                return True
        
        return False


def test_recognizer():
    """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ¹Ø±Ù"""
    print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª")
    print("=" * 50)
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Whisper Ø£ÙˆÙ„Ø§Ù‹
    try:
        recognizer = SpeechRecognizer(engine='whisper', language='ar')
        print("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Whisper Ø¨Ù†Ø¬Ø§Ø­!")
        return recognizer
    except Exception as e:
        print(f"âš ï¸ Whisper ØºÙŠØ± Ù…ØªØ§Ø­: {e}")
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Vosk
    try:
        recognizer = SpeechRecognizer(engine='vosk', language='ar')
        print("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Vosk Ø¨Ù†Ø¬Ø§Ø­!")
        return recognizer
    except Exception as e:
        print(f"âŒ Vosk ØºÙŠØ± Ù…ØªØ§Ø­: {e}")
        return None


if __name__ == "__main__":
    recognizer = test_recognizer()
    if recognizer:
        print("\nğŸ¤ Ø§Ø¨Ø¯Ø£ Ø¨Ø§Ù„ØªØ­Ø¯Ø«...")
        recognizer.start_recording()
        text = recognizer.record_and_recognize(duration=5)
        recognizer.stop_recording()
        print(f"âœ… Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø­ÙˆÙ„: {text}")

